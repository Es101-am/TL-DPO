{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOnFRO+tmZeOhrqG3FS95aZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7dfbf469fd874c90aa19096139518d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad5d98a11e874bc4a30748aa3ae22856",
              "IPY_MODEL_8017275c2f5344d39c9fc9324f913983",
              "IPY_MODEL_6212a7b64eb0439dba1cdc5166a636c2"
            ],
            "layout": "IPY_MODEL_8fe118d339014928965620d1a5aab1d4"
          }
        },
        "ad5d98a11e874bc4a30748aa3ae22856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07d81496cfb54edbb722b67b8562dd29",
            "placeholder": "​",
            "style": "IPY_MODEL_9d2389723c9141719d7571fac67e0c52",
            "value": "Map: 100%"
          }
        },
        "8017275c2f5344d39c9fc9324f913983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa9787106a6946c29f261066e165cab3",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_edb881249594455bbfe3176b8290ba9d",
            "value": 5000
          }
        },
        "6212a7b64eb0439dba1cdc5166a636c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9da07ba4cca454ab6afcd0007384e3c",
            "placeholder": "​",
            "style": "IPY_MODEL_5359f0f67aa74fb99d77ef4d50c83306",
            "value": " 5000/5000 [00:06&lt;00:00, 613.59 examples/s]"
          }
        },
        "8fe118d339014928965620d1a5aab1d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07d81496cfb54edbb722b67b8562dd29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d2389723c9141719d7571fac67e0c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa9787106a6946c29f261066e165cab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edb881249594455bbfe3176b8290ba9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9da07ba4cca454ab6afcd0007384e3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5359f0f67aa74fb99d77ef4d50c83306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0077a09bae048eb8205d574ca6ea92f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4a0dfa2d2ec4ef0b48407d3d3b94cad",
              "IPY_MODEL_0dcd6c8bdfe44104b9a432cab39600d2",
              "IPY_MODEL_4cf2538649e8423686bcadd384aa3457"
            ],
            "layout": "IPY_MODEL_79e5921e2d1149748836e9525aa9e6aa"
          }
        },
        "a4a0dfa2d2ec4ef0b48407d3d3b94cad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c89da91663754563aab61cafe193ff75",
            "placeholder": "​",
            "style": "IPY_MODEL_4fbea5bac75b4f27864953854ce516d3",
            "value": "Filter: 100%"
          }
        },
        "0dcd6c8bdfe44104b9a432cab39600d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d70c27995ec4484b882fe6462553eb0",
            "max": 4985,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_456d28e6001640de8eff69a3a0b6d393",
            "value": 4985
          }
        },
        "4cf2538649e8423686bcadd384aa3457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ba55d19084c4cabbc09dda27485827d",
            "placeholder": "​",
            "style": "IPY_MODEL_f158f2a5e52f49338357d7efc9c19606",
            "value": " 4985/4985 [00:00&lt;00:00, 101948.44 examples/s]"
          }
        },
        "79e5921e2d1149748836e9525aa9e6aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c89da91663754563aab61cafe193ff75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fbea5bac75b4f27864953854ce516d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d70c27995ec4484b882fe6462553eb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "456d28e6001640de8eff69a3a0b6d393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ba55d19084c4cabbc09dda27485827d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f158f2a5e52f49338357d7efc9c19606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df7c61a6e3774c7895ad5f153b69d3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40402075f96a4fa79e577915a9b2b8a8",
              "IPY_MODEL_f069ac43001c4a69bb54f2ace027f11a",
              "IPY_MODEL_ddcac69318724e5495acd156d5684336"
            ],
            "layout": "IPY_MODEL_c389b63219714c13bea6457034dd2728"
          }
        },
        "40402075f96a4fa79e577915a9b2b8a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4031e8e9fff468a97bce8ac46d19b26",
            "placeholder": "​",
            "style": "IPY_MODEL_1bf68b33de3040218d2b2b1c0f4b2786",
            "value": "Extracting prompt in train dataset: 100%"
          }
        },
        "f069ac43001c4a69bb54f2ace027f11a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d708c576dc7a45b4828569978011ac3a",
            "max": 4985,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a756cc5ed92432fb878fed1a246f3dd",
            "value": 4985
          }
        },
        "ddcac69318724e5495acd156d5684336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c1e6c5ac42549fda8c3095860c1b347",
            "placeholder": "​",
            "style": "IPY_MODEL_42dd37dfefcc4ddfb5bfe9241c9f9b59",
            "value": " 4985/4985 [00:00&lt;00:00, 6523.72 examples/s]"
          }
        },
        "c389b63219714c13bea6457034dd2728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4031e8e9fff468a97bce8ac46d19b26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bf68b33de3040218d2b2b1c0f4b2786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d708c576dc7a45b4828569978011ac3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a756cc5ed92432fb878fed1a246f3dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c1e6c5ac42549fda8c3095860c1b347": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42dd37dfefcc4ddfb5bfe9241c9f9b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8e25a6d54054897b5f6fbccb3144b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8eaa93af06d1479ab6da82dfedff93ae",
              "IPY_MODEL_134a4b19e7c54a9c8281a15a5aef82fe",
              "IPY_MODEL_018f3730321240e4a473288140159f95"
            ],
            "layout": "IPY_MODEL_f7be196e740c42e5b4e03761b1133649"
          }
        },
        "8eaa93af06d1479ab6da82dfedff93ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_313002be577b4da4aaf237320cda93ed",
            "placeholder": "​",
            "style": "IPY_MODEL_f0e42db944fc44b89242a9697b0faecf",
            "value": "Applying chat template to train dataset: 100%"
          }
        },
        "134a4b19e7c54a9c8281a15a5aef82fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_015fb09108aa4680b52bce00977238cb",
            "max": 4985,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83af9095332e4fbe8b7c682c4c8c4695",
            "value": 4985
          }
        },
        "018f3730321240e4a473288140159f95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1e29b424b614076b573dad326ce4060",
            "placeholder": "​",
            "style": "IPY_MODEL_43e6b4ecb26748cf82f572247ea584ca",
            "value": " 4985/4985 [00:00&lt;00:00, 10701.51 examples/s]"
          }
        },
        "f7be196e740c42e5b4e03761b1133649": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "313002be577b4da4aaf237320cda93ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0e42db944fc44b89242a9697b0faecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "015fb09108aa4680b52bce00977238cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83af9095332e4fbe8b7c682c4c8c4695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1e29b424b614076b573dad326ce4060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43e6b4ecb26748cf82f572247ea584ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2095302d22a49159f7ff48308a3f8c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d22dc149f9b41a581bfbd1da36a2d79",
              "IPY_MODEL_6cb3a52a4f8b4f77813c17d47065f386",
              "IPY_MODEL_0f7f90484881492e8a9ac29205b1d00c"
            ],
            "layout": "IPY_MODEL_86b41b0153c645b289925148f85ba09b"
          }
        },
        "3d22dc149f9b41a581bfbd1da36a2d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a598fb57ef0a472c9abbf91ea4bfa1a9",
            "placeholder": "​",
            "style": "IPY_MODEL_b911bbda54224ee7ac88f7ba70abef84",
            "value": "Tokenizing train dataset: 100%"
          }
        },
        "6cb3a52a4f8b4f77813c17d47065f386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cc268248e9b4d8897c8f17acea37775",
            "max": 4985,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1ef7cb349964ac78d27856f92ad3eca",
            "value": 4985
          }
        },
        "0f7f90484881492e8a9ac29205b1d00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f14b4d88d4824cd99c2bba2c0c8929b3",
            "placeholder": "​",
            "style": "IPY_MODEL_5398c80217f64b859756bbf878512787",
            "value": " 4985/4985 [00:07&lt;00:00, 637.61 examples/s]"
          }
        },
        "86b41b0153c645b289925148f85ba09b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a598fb57ef0a472c9abbf91ea4bfa1a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b911bbda54224ee7ac88f7ba70abef84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cc268248e9b4d8897c8f17acea37775": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1ef7cb349964ac78d27856f92ad3eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f14b4d88d4824cd99c2bba2c0c8929b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5398c80217f64b859756bbf878512787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Es101-am/TL-DPO/blob/main/DPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B59jiXbdrg03",
        "outputId": "29a374ab-506d-499e-9836-02fb7f52dd22"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May 21 08:26:29 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0             43W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zLSheQgyjjyM"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# Set model ID from Hugging Face Hub\n",
        "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "# Load tokenizer and model directly from Hugging Face\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",               # Automatically chooses device (use \"cpu\" if needed)\n",
        "    torch_dtype=torch.float32        # Required for CPU\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# List of prompts\n",
        "prompts = [\n",
        "   \"Can you guide me through the steps to create a personal monthly budget?\"\n",
        "\n",
        "]\n",
        "\n",
        "# Move model to the device once\n",
        "model.to(device)\n",
        "\n",
        "# Generate responses\n",
        "for prompt in prompts:\n",
        "    print(f\"\\nPrompt: {prompt}\\n{'-'*40}\")\n",
        "\n",
        "    # Tokenize the prompt and move to device\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Generate response\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=100,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            temperature=0.8,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # Decode and print the generated text\n",
        "    response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    print(\"Model response:\\n\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTHLvWEZkyIl",
        "outputId": "124cbb17-3df4-40e7-f94c-8ec26bc457f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Prompt: Can you guide me through the steps to create a personal monthly budget?\n",
            "----------------------------------------\n",
            "Model response:\n",
            " Can you guide me through the steps to create a personal monthly budget?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
        "\n",
        "# Enable gradient checkpointing\n",
        "model.gradient_checkpointing_enable()"
      ],
      "metadata": {
        "id": "Gt5b5sVXETqx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_trainable_params(model):\n",
        "    \"\"\"\n",
        "    Display a breakdown of trainable vs. non-trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    frozen_params = total_params - trainable_params\n",
        "\n",
        "    print(f\"Total Parameters: {total_params}\")\n",
        "    print(f\"Trainable Parameters: {trainable_params}\")\n",
        "    print(f\"Frozen Parameters: {frozen_params}\\n\")\n",
        "\n",
        "    print(\"Trainable parameter names:\")\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(f\"  - {name}\")\n",
        "\n",
        "    print(\"\\nFrozen parameter names:\")\n",
        "    for name, param in model.named_parameters():\n",
        "        if not param.requires_grad:\n",
        "            print(f\"  - {name}\")\n"
      ],
      "metadata": {
        "id": "hLvRzFGBGTX6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZzBrlm8GsKW",
        "outputId": "57f3018a-9caa-48da-8bb5-0d5fc622ae28"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(32000, 2048)\n",
            "    (layers): ModuleList(\n",
            "      (0-21): 22 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaAttention(\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
            "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
            "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
            "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
            "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "    (rotary_emb): LlamaRotaryEmbedding()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "# Define LoRA settings for adaptation in a causal language modeling task\n",
        "lora_settings = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\n",
        "        \"self_attn.q_proj\",\n",
        "        \"self_attn.k_proj\",\n",
        "        \"self_attn.v_proj\",\n",
        "        \"self_attn.o_proj\",\n",
        "        \"mlp.gate_proj\",\n",
        "        \"mlp.up_proj\",\n",
        "        \"mlp.down_proj\",\n",
        "    ],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "NtwwwAhiGvQ3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import get_peft_model\n",
        "\n",
        "# Apply the LoRA configuration to transform the base model into a PEFT-compatible model\n",
        "model = get_peft_model(model, peft_config=lora_settings)\n",
        "\n",
        "# Optional: review which layers are trainable after adaptation\n",
        "# summarize_trainable_params(model)\n"
      ],
      "metadata": {
        "id": "5TCfSiPlHEnq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
        "print(tokenizer)\n",
        "print(tokenizer.vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RfI2l7nIwA_",
        "outputId": "7d1fa9ab-58ac-4b75-a779-a2bafa60bab5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaTokenizerFast(name_or_path='TinyLlama/TinyLlama-1.1B-Chat-v1.0', vocab_size=32000, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
            "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            ")\n",
            "32000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the tokenizer includes a padding token\n",
        "if \"<pad>\" not in tokenizer.vocab:\n",
        "    num_tokens_added = tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
        "else:\n",
        "    num_tokens_added = 0\n",
        "\n",
        "# Resize the model's embedding layer if the tokenizer vocabulary was extended\n",
        "if num_tokens_added:\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    print(\"\\n🔧 Adjusted model embeddings to accommodate new tokenizer tokens\\n\")\n",
        "\n",
        "# Set the padding token ID in the model configuration\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "# Validate that the pad token is correctly assigned\n",
        "assert model.config.pad_token_id == tokenizer.pad_token_id, \"Mismatch in pad token IDs!\"\n",
        "\n",
        "# Display padding token info for verification\n",
        "print(f\"Pad Token ID → Tokenizer: {tokenizer.pad_token_id}, Model: {model.config.pad_token_id}\")\n",
        "\n",
        "# Confirm the end-of-sequence token alignment\n",
        "assert model.config.eos_token_id == tokenizer.eos_token_id, \"EOS token ID mismatch between model and tokenizer.\"\n",
        "\n",
        "# Align the tokenizer's max length with the model's context window\n",
        "tokenizer.model_max_length = model.config.max_position_embeddings\n",
        "\n",
        "# Display additional token information\n",
        "print(f\"EOS Token ID → {tokenizer.eos_token_id} | Decoded: {tokenizer.decode([tokenizer.eos_token_id])}\")\n",
        "print(f\"BOS Token ID → {model.config.bos_token_id} | Decoded: {tokenizer.decode([model.config.bos_token_id])}\")\n",
        "\n",
        "# Optionally inspect the full tokenizer object\n",
        "print(\"Tokenizer overview:\", tokenizer)\n",
        "\n",
        "# Alternative padding handling strategy if needed:\n",
        "# tokenizer.pad_token = tokenizer.unk_token\n",
        "# tokenizer.pad_token_id = tokenizer.unk_token_id\n",
        "# tokenizer.padding_side = \"left\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHvw4duHI5rY",
        "outputId": "b8a02124-994e-40f3-cdb5-c4b11a6cfee9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔧 Adjusted model embeddings to accommodate new tokenizer tokens\n",
            "\n",
            "Pad Token ID → Tokenizer: 32000, Model: 32000\n",
            "EOS Token ID → 2 | Decoded: </s>\n",
            "BOS Token ID → 1 | Decoded: <s>\n",
            "Tokenizer overview: LlamaTokenizerFast(name_or_path='TinyLlama/TinyLlama-1.1B-Chat-v1.0', vocab_size=32000, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
            "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t32000: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Special tokens map:\", tokenizer.special_tokens_map)\n",
        "\n",
        "# Optionally, print all special tokens (commented out in your image)\n",
        "# print(\"All special tokens:\", tokenizer.all_special_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC3h3oGvJc5q",
        "outputId": "a27eb2b8-a439-4fa1-a8ae-297d4bba0aab"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Special tokens map: {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import TextStreamer\n",
        "from peft import PeftModel\n",
        "import gc  # Garbage collection to free unused memory\n",
        "\n",
        "def run_streaming_inference(user_input, model_variant, adapter_path=\"\"):\n",
        "    # Choose which model to use for inference\n",
        "    if model_variant == \"base\":\n",
        "        active_model = model\n",
        "    elif model_variant == \"fine-tuned\":\n",
        "        active_model = PeftModel.from_pretrained(model, adapter_path).to(\"cuda\")\n",
        "\n",
        "        # Check for any parameters still on CPU (debugging)\n",
        "        for name, param in active_model.named_parameters():\n",
        "            if param.device.type == \"cpu\":\n",
        "                print(f\"⚠️ Parameter still on CPU: {name}\")\n",
        "    else:\n",
        "        raise ValueError(\"model_variant must be 'base' or 'fine-tuned'\")\n",
        "\n",
        "    # Set caching behavior\n",
        "    active_model.config.use_cache = True\n",
        "\n",
        "    # Format prompt using LLaMA-style instruction tags\n",
        "    instr_start, instr_end = \"[INST]\", \"[/INST]\"\n",
        "    structured_prompt = f\"{instr_start} {user_input.strip()} {instr_end}\"\n",
        "    print(f\"Formatted prompt:\\n{structured_prompt}\")\n",
        "\n",
        "    # Tokenize and move input to GPU\n",
        "    encoded_input = tokenizer([structured_prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Remove token_type_ids if not supported\n",
        "    encoded_input.pop(\"token_type_ids\", None)\n",
        "\n",
        "    # Create a streaming output handler\n",
        "    output_streamer = TextStreamer(tokenizer)\n",
        "\n",
        "    # Device confirmation logs\n",
        "    print(f\"Model running on: {next(active_model.parameters()).device}\")\n",
        "    print(f\"Input device: {encoded_input['input_ids'].device}\")\n",
        "\n",
        "    # Run generation with streaming enabled\n",
        "    _ = active_model.generate(\n",
        "        **encoded_input,\n",
        "        streamer=output_streamer,\n",
        "        max_new_tokens=50,\n",
        "        pad_token_id=tokenizer.pad_token_id\n",
        "    )\n",
        "\n",
        "    # Memory cleanup after generation\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"Releasing GPU memory...\")\n",
        "        torch.cuda.empty_cache()\n",
        "    else:\n",
        "        print(\"Running CPU memory cleanup...\")\n",
        "    gc.collect()\n"
      ],
      "metadata": {
        "id": "fIJ3FnkpJe9m"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(model_type, checkpoint=''):\n",
        "    questions = [\n",
        "        \"Can you guide me through the steps to create a personal monthly budget?\",\n",
        "    ]\n",
        "\n",
        "    # Optionally provide some correct answers for comparison. This is for manual eval.\n",
        "    answers = [\n",
        "        \"To create a personal monthly budget, pay yourself first, track and limit spending, save for emergencies, plan for retirement early, and seek financial advice when needed.\",\n",
        "    ]\n",
        "\n",
        "    for question, answer in zip(questions, answers):\n",
        "        run_streaming_inference(question, model_type, checkpoint)\n",
        "        # print(\"Correct Answer:\", answer)\n",
        "        print('\\n\\n')"
      ],
      "metadata": {
        "id": "NZ9YKGRsJ2eH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.generation_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF6ER9BRLg1o",
        "outputId": "01b2abc9-0882-4639-d04e-bcdd1bbbd497"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"max_length\": 2048,\n",
            "  \"pad_token_id\": 0\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(\"base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SzaAXBgLw-r",
        "outputId": "92a80417-2775-41bb-9fa5-14001d8b0435"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formatted prompt:\n",
            "[INST] Can you guide me through the steps to create a personal monthly budget? [/INST]\n",
            "Model running on: cuda:0\n",
            "Input device: cuda:0\n",
            "<s> [INST] Can you guide me through the steps to create a personal monthly budget? [/INST]\n",
            "\n",
            "Step 1: Determine your income and expenses\n",
            "\n",
            "1. Determine your monthly income by subtracting your monthly expenses from your monthly income.\n",
            "\n",
            "2. Calculate your monthly expenses\n",
            "Releasing GPU memory...\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/datasets/OpenAssistant/oasst1/resolve/main/2023-04-12_oasst_ready.trees.jsonl.gz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev7z8AneMRez",
        "outputId": "46719065-86df-4b7c-bde1-2801feeb1f04"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-21 11:12:34--  https://huggingface.co/datasets/OpenAssistant/oasst1/resolve/main/2023-04-12_oasst_ready.trees.jsonl.gz\n",
            "Resolving huggingface.co (huggingface.co)... 108.138.246.79, 108.138.246.71, 108.138.246.85, ...\n",
            "Connecting to huggingface.co (huggingface.co)|108.138.246.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/1f/ee/1fee66b6fc467613ff62f20bb7139c905acb4df617d807af37290112c3b672e5/2a9a8fd343e9b28e04a895a669d3253f82d93e9c174d440199ae19d5fafbdff7?response-content-disposition=inline%3B+filename*%3DUTF-8%27%272023-04-12_oasst_ready.trees.jsonl.gz%3B+filename%3D%222023-04-12_oasst_ready.trees.jsonl.gz%22%3B&response-content-type=application%2Fgzip&Expires=1747829554&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NzgyOTU1NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8xZi9lZS8xZmVlNjZiNmZjNDY3NjEzZmY2MmYyMGJiNzEzOWM5MDVhY2I0ZGY2MTdkODA3YWYzNzI5MDExMmMzYjY3MmU1LzJhOWE4ZmQzNDNlOWIyOGUwNGE4OTVhNjY5ZDMyNTNmODJkOTNlOWMxNzRkNDQwMTk5YWUxOWQ1ZmFmYmRmZjc%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=MPqkKYGFrG9KHRPmZB02uXQtJg5BsTTKQev7jelJvBvbqJkklODVOoGTEtLHGC%7ET8VewEZSP5HUDYocIUqwkYb014fusFcDW0Kf9b66YNc563BvBo6go7lLHgAu43o5uIWgK48GZymzeVKlXjZwUWh6AxwWnth23uP6vSS%7EmPDgeMw2uM%7E3pGt5gpj8prtcKq53KerpcU-a5QsGflsJknerxhberpgPIgrrlSkHxffNTBzmzI-NCQlRIrvdaXfIqI4kFRG6zklwbkjytOdf%7EHNcU4enRZfStMHE8xAlawDEqbADTnrauebSBwIO29gCRi92zjhPTYWiEc6rTlVudIw__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-05-21 11:12:34--  https://cdn-lfs.hf.co/repos/1f/ee/1fee66b6fc467613ff62f20bb7139c905acb4df617d807af37290112c3b672e5/2a9a8fd343e9b28e04a895a669d3253f82d93e9c174d440199ae19d5fafbdff7?response-content-disposition=inline%3B+filename*%3DUTF-8%27%272023-04-12_oasst_ready.trees.jsonl.gz%3B+filename%3D%222023-04-12_oasst_ready.trees.jsonl.gz%22%3B&response-content-type=application%2Fgzip&Expires=1747829554&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NzgyOTU1NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8xZi9lZS8xZmVlNjZiNmZjNDY3NjEzZmY2MmYyMGJiNzEzOWM5MDVhY2I0ZGY2MTdkODA3YWYzNzI5MDExMmMzYjY3MmU1LzJhOWE4ZmQzNDNlOWIyOGUwNGE4OTVhNjY5ZDMyNTNmODJkOTNlOWMxNzRkNDQwMTk5YWUxOWQ1ZmFmYmRmZjc%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=MPqkKYGFrG9KHRPmZB02uXQtJg5BsTTKQev7jelJvBvbqJkklODVOoGTEtLHGC%7ET8VewEZSP5HUDYocIUqwkYb014fusFcDW0Kf9b66YNc563BvBo6go7lLHgAu43o5uIWgK48GZymzeVKlXjZwUWh6AxwWnth23uP6vSS%7EmPDgeMw2uM%7E3pGt5gpj8prtcKq53KerpcU-a5QsGflsJknerxhberpgPIgrrlSkHxffNTBzmzI-NCQlRIrvdaXfIqI4kFRG6zklwbkjytOdf%7EHNcU4enRZfStMHE8xAlawDEqbADTnrauebSBwIO29gCRi92zjhPTYWiEc6rTlVudIw__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.155.202.83, 18.155.202.10, 18.155.202.123, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.155.202.83|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34145252 (33M) [application/gzip]\n",
            "Saving to: ‘2023-04-12_oasst_ready.trees.jsonl.gz’\n",
            "\n",
            "2023-04-12_oasst_re 100%[===================>]  32.56M  42.8MB/s    in 0.8s    \n",
            "\n",
            "2025-05-21 11:12:35 (42.8 MB/s) - ‘2023-04-12_oasst_ready.trees.jsonl.gz’ saved [34145252/34145252]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the JSONL file using pandas to avoid schema conflicts\n",
        "df = pd.read_json(\"2023-04-12_oasst_ready.trees.jsonl.gz\", lines=True)\n"
      ],
      "metadata": {
        "id": "oWIo1DWTi4cA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Keep only the first 5,000 rows\n",
        "df_subset = df.head(5000).reset_index(drop=True)\n",
        "\n",
        "# Convert to Hugging Face Dataset\n",
        "data = Dataset.from_pandas(df_subset)\n",
        "\n"
      ],
      "metadata": {
        "id": "qWRJ6uKWjJJm"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row = data[0]  # first conversation tree\n",
        "root_prompt = row.get(\"prompt\", {}).get(\"text\")\n",
        "\n",
        "# Collect assistant replies\n",
        "assistant_replies = [\n",
        "    reply for reply in row.get(\"prompt\", {}).get(\"replies\", [])\n",
        "    if reply.get(\"role\") == \"assistant\" and reply.get(\"rank\") is not None\n",
        "]\n",
        "\n",
        "# Sort by rank (0 = best, higher = worse)\n",
        "assistant_replies = sorted(assistant_replies, key=lambda r: r[\"rank\"])\n",
        "\n",
        "# Extract chosen and rejected if available\n",
        "chosen = assistant_replies[0][\"text\"] if len(assistant_replies) > 0 else None\n",
        "rejected = assistant_replies[1][\"text\"] if len(assistant_replies) > 1 else None\n",
        "\n",
        "# Display results\n",
        "print(\"Prompt:\\n\", root_prompt)\n",
        "print(\"\\nChosen Response (rank 0):\\n\", chosen)\n",
        "print(\"\\nRejected Response (rank 1 or more):\\n\", rejected)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3Lphh2ojWbA",
        "outputId": "1f6c7762-8f2c-4c76-9008-168e002f5610"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            " Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.\n",
            "\n",
            "Chosen Response (rank 0):\n",
            " \"Monopsony\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as the employer has little incentive to increase wages or provide better working conditions.\n",
            "\n",
            "Recent research has identified potential monopsonies in industries such as retail and fast food, where a few large companies control a significant portion of the market (Bivens & Mishel, 2013). In these industries, workers often face low wages, limited benefits, and reduced bargaining power, leading to a situation where they are dependent on the employer for their livelihood. This dependence can result in further suppression of wages and a decline in working conditions.\n",
            "\n",
            "Overall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue.\n",
            "\n",
            "References:\n",
            "Bivens, J., & Mishel, L. (2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.\n",
            "\n",
            "Rejected Response (rank 1 or more):\n",
            " Monopsony is a market structure in which there is a single buyer in a market. In the context of labor markets, a monopsony occurs when there is only one employer in a particular industry or geographic area, giving that employer significant power over the wages and working conditions of workers. This results in a situation where the employer has the ability to suppress wages and reduce the bargaining power of workers.\n",
            "\n",
            "Research has shown that the existence of monopsony power in labor markets can have negative effects on workers, such as lower wages, reduced benefits, and limited job opportunities. For example, a study by Autor, Dorn, and Hanson (2013) found evidence of monopsony power in certain U.S. labor markets, resulting in lower wages and reduced job opportunities for workers. Similarly, another study by Bharadwaj, Black, and Kolesnikova (2019) found that the presence of a single dominant employer in a local labor market was associated with lower wages for workers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract prompt text from the first row\n",
        "text = data[0][\"prompt\"][\"text\"]\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = tokenizer.encode(text, add_special_tokens=True)\n",
        "\n",
        "# Decode back to text\n",
        "decoded_text = tokenizer.decode(tokens)\n",
        "\n",
        "# Print tokens and decoded text\n",
        "print(\"Token IDs:\", tokens)\n",
        "print(\"Decoded Text:\", decoded_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zUJV4CPlJhV",
        "outputId": "ce56fbef-6945-4a2f-fc36-e5e67bb78c88"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs: [1, 1815, 366, 2436, 263, 3273, 18707, 1048, 278, 29527, 749, 310, 278, 1840, 376, 3712, 459, 1100, 29891, 29908, 297, 7766, 1199, 29973, 3529, 671, 6455, 4475, 304, 7037, 1601, 459, 1100, 583, 297, 278, 23390, 9999, 322, 274, 568, 8018, 5925, 29889]\n",
            "Decoded Text: <s> Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = model_id.split(\"/\")[-1]\n",
        "dataset_name = \"2023-04-12_oasst_ready.trees\"\n",
        "\n",
        "context_length = 512\n",
        "grad_accum = 16\n",
        "batch_size = 1\n",
        "fine_tune_tag = 'chat-DPO'\n",
        "\n",
        "epochs = 0.1\n",
        "save_dir = f'./results/{model_name}_{dataset_name}_{epochs}_epochs_{context_length}_ctx_{fine_tune_tag}'\n",
        "\n",
        "# Optional step-based directory naming\n",
        "# steps = 16\n",
        "# save_dir = f'./results/{model_name}_{dataset_name}_{steps}_steps_{context_length}_ctx_{fine_tune_tag}'\n",
        "\n",
        "print(save_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXkZgi9Rlt77",
        "outputId": "9294ed48-0482-4901-afa0-b129b346007f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./results/TinyLlama-1.1B-Chat-v1.0_2023-04-12_oasst_ready.trees_0.1_epochs_512_ctx_chat-DPO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "from trl import DPOTrainer, DPOConfig\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"steps\",\n",
        "    do_eval=True,\n",
        "    eval_steps=25,\n",
        "    optim=\"adamw_torch\",\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=8,\n",
        "    per_device_eval_batch_size=1,\n",
        "    log_level=\"debug\",\n",
        "    save_steps=25,\n",
        "    logging_steps=1,\n",
        "    learning_rate=1e-6,\n",
        "    num_train_epochs=1,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "# dpo_config = DPOConfig(\n",
        "#     beta=0.1,\n",
        "#     max_prompt_length=256,\n",
        "#     max_length=512,\n",
        "#     loss_type=\"sigmoid\"\n",
        "# )"
      ],
      "metadata": {
        "id": "AeSM9CYvmvTZ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dpo_sample(example):\n",
        "    prompt_text = example.get(\"prompt\", {}).get(\"text\", \"\")\n",
        "\n",
        "    # Get assistant replies with valid ranks\n",
        "    replies = example.get(\"prompt\", {}).get(\"replies\", [])\n",
        "    assistant_replies = [r for r in replies if r.get(\"role\") == \"assistant\" and r.get(\"rank\") is not None]\n",
        "\n",
        "    # Sort replies by rank (0 = best)\n",
        "    assistant_replies = sorted(assistant_replies, key=lambda r: r[\"rank\"])\n",
        "\n",
        "    if len(assistant_replies) < 2:\n",
        "        return None  # skip if we don't have both chosen & rejected\n",
        "\n",
        "    return {\n",
        "        \"prompt\": prompt_text.strip(),\n",
        "        \"chosen\": assistant_replies[0][\"text\"].strip(),   # rank 0\n",
        "        \"rejected\": assistant_replies[1][\"text\"].strip(), # rank 1+\n",
        "    }\n",
        "\n",
        "# Filter + preprocess\n",
        "processed_data = data.map(prepare_dpo_sample, remove_columns=data.column_names)\n",
        "processed_data = processed_data.filter(lambda x: x is not None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "7dfbf469fd874c90aa19096139518d2f",
            "ad5d98a11e874bc4a30748aa3ae22856",
            "8017275c2f5344d39c9fc9324f913983",
            "6212a7b64eb0439dba1cdc5166a636c2",
            "8fe118d339014928965620d1a5aab1d4",
            "07d81496cfb54edbb722b67b8562dd29",
            "9d2389723c9141719d7571fac67e0c52",
            "fa9787106a6946c29f261066e165cab3",
            "edb881249594455bbfe3176b8290ba9d",
            "a9da07ba4cca454ab6afcd0007384e3c",
            "5359f0f67aa74fb99d77ef4d50c83306",
            "e0077a09bae048eb8205d574ca6ea92f",
            "a4a0dfa2d2ec4ef0b48407d3d3b94cad",
            "0dcd6c8bdfe44104b9a432cab39600d2",
            "4cf2538649e8423686bcadd384aa3457",
            "79e5921e2d1149748836e9525aa9e6aa",
            "c89da91663754563aab61cafe193ff75",
            "4fbea5bac75b4f27864953854ce516d3",
            "1d70c27995ec4484b882fe6462553eb0",
            "456d28e6001640de8eff69a3a0b6d393",
            "3ba55d19084c4cabbc09dda27485827d",
            "f158f2a5e52f49338357d7efc9c19606"
          ]
        },
        "id": "f0J0Bfxso9XY",
        "outputId": "7cc3ec5f-a8f5-4555-933e-00fa895080f9"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7dfbf469fd874c90aa19096139518d2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/4985 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0077a09bae048eb8205d574ca6ea92f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import DPOConfig\n",
        "\n",
        "dpo_config = DPOConfig(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    logging_steps=10,\n",
        "    save_steps=25,\n",
        "    num_train_epochs=1,\n",
        "    eval_strategy=\"no\",\n",
        "    learning_rate=1e-6,\n",
        "    report_to=None,\n",
        "    max_prompt_length=256,\n",
        "    max_length=512,\n",
        "    loss_type=\"sigmoid\",\n",
        "    beta=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "LpSWSrXwqgdu"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import DPOTrainer\n",
        "\n",
        "trainer = DPOTrainer(\n",
        "    model=model,\n",
        "    ref_model=None,\n",
        "    args=dpo_config,\n",
        "    train_dataset=processed_data,\n",
        "    processing_class=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "df7c61a6e3774c7895ad5f153b69d3d4",
            "40402075f96a4fa79e577915a9b2b8a8",
            "f069ac43001c4a69bb54f2ace027f11a",
            "ddcac69318724e5495acd156d5684336",
            "c389b63219714c13bea6457034dd2728",
            "a4031e8e9fff468a97bce8ac46d19b26",
            "1bf68b33de3040218d2b2b1c0f4b2786",
            "d708c576dc7a45b4828569978011ac3a",
            "5a756cc5ed92432fb878fed1a246f3dd",
            "7c1e6c5ac42549fda8c3095860c1b347",
            "42dd37dfefcc4ddfb5bfe9241c9f9b59",
            "a8e25a6d54054897b5f6fbccb3144b9a",
            "8eaa93af06d1479ab6da82dfedff93ae",
            "134a4b19e7c54a9c8281a15a5aef82fe",
            "018f3730321240e4a473288140159f95",
            "f7be196e740c42e5b4e03761b1133649",
            "313002be577b4da4aaf237320cda93ed",
            "f0e42db944fc44b89242a9697b0faecf",
            "015fb09108aa4680b52bce00977238cb",
            "83af9095332e4fbe8b7c682c4c8c4695",
            "f1e29b424b614076b573dad326ce4060",
            "43e6b4ecb26748cf82f572247ea584ca",
            "e2095302d22a49159f7ff48308a3f8c5",
            "3d22dc149f9b41a581bfbd1da36a2d79",
            "6cb3a52a4f8b4f77813c17d47065f386",
            "0f7f90484881492e8a9ac29205b1d00c",
            "86b41b0153c645b289925148f85ba09b",
            "a598fb57ef0a472c9abbf91ea4bfa1a9",
            "b911bbda54224ee7ac88f7ba70abef84",
            "6cc268248e9b4d8897c8f17acea37775",
            "f1ef7cb349964ac78d27856f92ad3eca",
            "f14b4d88d4824cd99c2bba2c0c8929b3",
            "5398c80217f64b859756bbf878512787"
          ]
        },
        "id": "yBJ0YV4xqjbd",
        "outputId": "3991e624-5e9f-4324-a2da-0f2398fba561"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting prompt in train dataset:   0%|          | 0/4985 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df7c61a6e3774c7895ad5f153b69d3d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Applying chat template to train dataset:   0%|          | 0/4985 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8e25a6d54054897b5f6fbccb3144b9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/4985 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2095302d22a49159f7ff48308a3f8c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4985' max='4985' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4985/4985 37:50, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.683300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.684400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.686000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.686300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.687100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.684800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.686200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.685600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.686600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.689000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.687400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.685600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.689700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.685300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.686700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.685200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.688900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.688900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.691200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.688900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.689800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.694100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.693000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.691800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.693900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.693600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.693300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.692300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.693300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.690900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.691900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.692800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.691200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.693100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.693200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.690200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.696800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.692000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.691800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.692300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.691800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.691100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.693000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.694900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.691500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.689800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.692200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.693300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.692300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.692400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.692600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.691900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.693900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.691500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.694400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.695100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.688300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.692700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.693900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.689900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.694600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.695800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.687000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.695900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.689400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.690600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.696100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.689200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.690100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.684600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.689900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.688800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.692900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.693700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.686000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.693000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.695700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.688100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.690100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.690000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.683100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.692900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.688900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.694900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.694900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.688300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.686800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.691100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.693900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.691600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.690100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.682900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.689300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.691500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.698400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.689200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.691800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.691500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.691500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>0.696200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.700700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>0.696500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.683900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.688900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.692600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>0.696100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.697400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>0.690900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.691900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>0.690600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.695800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.692300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.685700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.692900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.692000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.686000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>0.689400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.695900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>0.694600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.690500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>0.698500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.692500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.690600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.689000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>0.692300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.692900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>0.688200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.696000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>0.688500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>0.689600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.688100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.684900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>0.692500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1370</td>\n",
              "      <td>0.687700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>0.686600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1390</td>\n",
              "      <td>0.701600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.687300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1410</td>\n",
              "      <td>0.689700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1420</td>\n",
              "      <td>0.689100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1430</td>\n",
              "      <td>0.686000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>0.688900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.689600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1460</td>\n",
              "      <td>0.686400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1470</td>\n",
              "      <td>0.696600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1480</td>\n",
              "      <td>0.681800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1490</td>\n",
              "      <td>0.692500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.697700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1510</td>\n",
              "      <td>0.690500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1520</td>\n",
              "      <td>0.683300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1530</td>\n",
              "      <td>0.684400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1540</td>\n",
              "      <td>0.694600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.691500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>0.688900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1570</td>\n",
              "      <td>0.687000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1580</td>\n",
              "      <td>0.695400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1590</td>\n",
              "      <td>0.696100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.690100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1610</td>\n",
              "      <td>0.695000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1620</td>\n",
              "      <td>0.678800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1630</td>\n",
              "      <td>0.693900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1640</td>\n",
              "      <td>0.697000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.688700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1660</td>\n",
              "      <td>0.688400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1670</td>\n",
              "      <td>0.695800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1680</td>\n",
              "      <td>0.681000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1690</td>\n",
              "      <td>0.684600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.688500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1710</td>\n",
              "      <td>0.682200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1720</td>\n",
              "      <td>0.696500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1730</td>\n",
              "      <td>0.700800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1740</td>\n",
              "      <td>0.688000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.694600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1760</td>\n",
              "      <td>0.681300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1770</td>\n",
              "      <td>0.694800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1780</td>\n",
              "      <td>0.692100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1790</td>\n",
              "      <td>0.695100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.679400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1810</td>\n",
              "      <td>0.702800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1820</td>\n",
              "      <td>0.674200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1830</td>\n",
              "      <td>0.687200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1840</td>\n",
              "      <td>0.687900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.702800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1860</td>\n",
              "      <td>0.694100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1870</td>\n",
              "      <td>0.687100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1880</td>\n",
              "      <td>0.691100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1890</td>\n",
              "      <td>0.682900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.691300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1910</td>\n",
              "      <td>0.701600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1920</td>\n",
              "      <td>0.672000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1930</td>\n",
              "      <td>0.687200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1940</td>\n",
              "      <td>0.699700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.691000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1960</td>\n",
              "      <td>0.696100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1970</td>\n",
              "      <td>0.688600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1980</td>\n",
              "      <td>0.678500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990</td>\n",
              "      <td>0.691700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.688100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2010</td>\n",
              "      <td>0.692700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2020</td>\n",
              "      <td>0.686900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2030</td>\n",
              "      <td>0.684700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2040</td>\n",
              "      <td>0.689300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.687200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2060</td>\n",
              "      <td>0.688400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2070</td>\n",
              "      <td>0.690700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2080</td>\n",
              "      <td>0.680400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2090</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.690300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2110</td>\n",
              "      <td>0.691100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2120</td>\n",
              "      <td>0.691700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2130</td>\n",
              "      <td>0.690900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2140</td>\n",
              "      <td>0.694100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.701600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2160</td>\n",
              "      <td>0.690100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2170</td>\n",
              "      <td>0.695700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2180</td>\n",
              "      <td>0.672300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2190</td>\n",
              "      <td>0.690000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.680200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2210</td>\n",
              "      <td>0.682300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2220</td>\n",
              "      <td>0.708400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2230</td>\n",
              "      <td>0.685800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2240</td>\n",
              "      <td>0.690300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.683500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2260</td>\n",
              "      <td>0.683900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2270</td>\n",
              "      <td>0.682700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2280</td>\n",
              "      <td>0.689800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2290</td>\n",
              "      <td>0.693500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.692300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2310</td>\n",
              "      <td>0.691000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2320</td>\n",
              "      <td>0.692600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2330</td>\n",
              "      <td>0.693700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.682500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.682500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2360</td>\n",
              "      <td>0.689100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2370</td>\n",
              "      <td>0.696400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2380</td>\n",
              "      <td>0.691800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2390</td>\n",
              "      <td>0.686500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.701900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2410</td>\n",
              "      <td>0.690900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2420</td>\n",
              "      <td>0.691500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2430</td>\n",
              "      <td>0.690000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2440</td>\n",
              "      <td>0.699600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.685200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2460</td>\n",
              "      <td>0.683000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2470</td>\n",
              "      <td>0.683100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2480</td>\n",
              "      <td>0.690900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2490</td>\n",
              "      <td>0.688400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.676200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2510</td>\n",
              "      <td>0.708900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2520</td>\n",
              "      <td>0.687400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2530</td>\n",
              "      <td>0.698700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2540</td>\n",
              "      <td>0.683300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.680700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2560</td>\n",
              "      <td>0.692500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2570</td>\n",
              "      <td>0.693400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2580</td>\n",
              "      <td>0.686700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2590</td>\n",
              "      <td>0.664500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.692000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2610</td>\n",
              "      <td>0.701200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2620</td>\n",
              "      <td>0.688100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2630</td>\n",
              "      <td>0.689100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2640</td>\n",
              "      <td>0.704500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.699500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2660</td>\n",
              "      <td>0.710100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2670</td>\n",
              "      <td>0.689400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2680</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2690</td>\n",
              "      <td>0.690400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.697300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2710</td>\n",
              "      <td>0.691300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2720</td>\n",
              "      <td>0.680500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2730</td>\n",
              "      <td>0.672000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2740</td>\n",
              "      <td>0.686800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.679800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2760</td>\n",
              "      <td>0.683000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2770</td>\n",
              "      <td>0.682200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2780</td>\n",
              "      <td>0.699900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2790</td>\n",
              "      <td>0.684600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.686900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2810</td>\n",
              "      <td>0.684200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2820</td>\n",
              "      <td>0.695700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2830</td>\n",
              "      <td>0.684600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2840</td>\n",
              "      <td>0.686100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.691500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2860</td>\n",
              "      <td>0.685900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2870</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2880</td>\n",
              "      <td>0.683100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2890</td>\n",
              "      <td>0.679800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.686100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2910</td>\n",
              "      <td>0.691000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2920</td>\n",
              "      <td>0.686000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2930</td>\n",
              "      <td>0.700200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2940</td>\n",
              "      <td>0.687000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>0.683100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2960</td>\n",
              "      <td>0.690100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2970</td>\n",
              "      <td>0.697100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2980</td>\n",
              "      <td>0.679000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2990</td>\n",
              "      <td>0.692800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.679100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3010</td>\n",
              "      <td>0.674800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3020</td>\n",
              "      <td>0.690600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3030</td>\n",
              "      <td>0.708000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3040</td>\n",
              "      <td>0.691300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>0.681200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3060</td>\n",
              "      <td>0.693400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3070</td>\n",
              "      <td>0.690500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3080</td>\n",
              "      <td>0.694300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3090</td>\n",
              "      <td>0.689600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.702900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3110</td>\n",
              "      <td>0.692800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3120</td>\n",
              "      <td>0.682500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3130</td>\n",
              "      <td>0.680300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3140</td>\n",
              "      <td>0.682300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3150</td>\n",
              "      <td>0.673200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3160</td>\n",
              "      <td>0.682200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3170</td>\n",
              "      <td>0.681500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3180</td>\n",
              "      <td>0.691300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3190</td>\n",
              "      <td>0.684700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.697000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3210</td>\n",
              "      <td>0.686900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3220</td>\n",
              "      <td>0.696000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3230</td>\n",
              "      <td>0.689500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3240</td>\n",
              "      <td>0.698800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>0.671900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3260</td>\n",
              "      <td>0.678900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3270</td>\n",
              "      <td>0.679300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3280</td>\n",
              "      <td>0.690300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3290</td>\n",
              "      <td>0.693700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.688300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3310</td>\n",
              "      <td>0.681200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3320</td>\n",
              "      <td>0.676400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3330</td>\n",
              "      <td>0.689200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3340</td>\n",
              "      <td>0.679200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3350</td>\n",
              "      <td>0.689800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3360</td>\n",
              "      <td>0.688100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3370</td>\n",
              "      <td>0.698500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3380</td>\n",
              "      <td>0.682900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3390</td>\n",
              "      <td>0.678000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.678400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3410</td>\n",
              "      <td>0.682200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3420</td>\n",
              "      <td>0.685100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3430</td>\n",
              "      <td>0.675700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3440</td>\n",
              "      <td>0.671300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3450</td>\n",
              "      <td>0.676000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3460</td>\n",
              "      <td>0.701700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3470</td>\n",
              "      <td>0.679700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3480</td>\n",
              "      <td>0.690200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3490</td>\n",
              "      <td>0.690800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.687200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3510</td>\n",
              "      <td>0.703400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3520</td>\n",
              "      <td>0.676900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3530</td>\n",
              "      <td>0.685100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3540</td>\n",
              "      <td>0.687200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3550</td>\n",
              "      <td>0.681700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3560</td>\n",
              "      <td>0.696500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3570</td>\n",
              "      <td>0.684900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3580</td>\n",
              "      <td>0.693000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3590</td>\n",
              "      <td>0.679700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.678900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3610</td>\n",
              "      <td>0.699000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3620</td>\n",
              "      <td>0.699100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3630</td>\n",
              "      <td>0.685800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3640</td>\n",
              "      <td>0.679600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3650</td>\n",
              "      <td>0.689100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3660</td>\n",
              "      <td>0.692300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3670</td>\n",
              "      <td>0.694300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3680</td>\n",
              "      <td>0.697600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3690</td>\n",
              "      <td>0.669200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.686500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3710</td>\n",
              "      <td>0.681800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3720</td>\n",
              "      <td>0.688300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3730</td>\n",
              "      <td>0.697400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3740</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>0.697200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3760</td>\n",
              "      <td>0.708200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3770</td>\n",
              "      <td>0.683100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3780</td>\n",
              "      <td>0.697700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3790</td>\n",
              "      <td>0.679700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.674700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3810</td>\n",
              "      <td>0.695900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3820</td>\n",
              "      <td>0.684200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3830</td>\n",
              "      <td>0.682800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3840</td>\n",
              "      <td>0.696600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3850</td>\n",
              "      <td>0.677900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3860</td>\n",
              "      <td>0.670600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3870</td>\n",
              "      <td>0.677800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3880</td>\n",
              "      <td>0.692300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3890</td>\n",
              "      <td>0.681600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.687100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3910</td>\n",
              "      <td>0.682900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3920</td>\n",
              "      <td>0.681500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3930</td>\n",
              "      <td>0.683200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3940</td>\n",
              "      <td>0.689900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3950</td>\n",
              "      <td>0.697600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3960</td>\n",
              "      <td>0.690000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3970</td>\n",
              "      <td>0.681200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3980</td>\n",
              "      <td>0.677400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3990</td>\n",
              "      <td>0.682600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.690800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4010</td>\n",
              "      <td>0.712700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4020</td>\n",
              "      <td>0.702800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4030</td>\n",
              "      <td>0.698200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4040</td>\n",
              "      <td>0.693900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4050</td>\n",
              "      <td>0.665900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4060</td>\n",
              "      <td>0.661300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4070</td>\n",
              "      <td>0.673700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4080</td>\n",
              "      <td>0.671900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4090</td>\n",
              "      <td>0.701500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.704900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4110</td>\n",
              "      <td>0.680400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4120</td>\n",
              "      <td>0.697000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4130</td>\n",
              "      <td>0.690300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4140</td>\n",
              "      <td>0.677600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4150</td>\n",
              "      <td>0.672700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4160</td>\n",
              "      <td>0.669300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4170</td>\n",
              "      <td>0.693800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4180</td>\n",
              "      <td>0.700200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4190</td>\n",
              "      <td>0.705500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.692300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4210</td>\n",
              "      <td>0.693500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4220</td>\n",
              "      <td>0.695900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4230</td>\n",
              "      <td>0.676000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4240</td>\n",
              "      <td>0.701400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4250</td>\n",
              "      <td>0.701500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4260</td>\n",
              "      <td>0.662400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4270</td>\n",
              "      <td>0.699000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4280</td>\n",
              "      <td>0.681700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4290</td>\n",
              "      <td>0.698100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.692100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4310</td>\n",
              "      <td>0.707000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4320</td>\n",
              "      <td>0.689000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4330</td>\n",
              "      <td>0.676000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4340</td>\n",
              "      <td>0.686600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4350</td>\n",
              "      <td>0.682900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4360</td>\n",
              "      <td>0.671900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4370</td>\n",
              "      <td>0.680900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4380</td>\n",
              "      <td>0.681100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4390</td>\n",
              "      <td>0.679900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.685200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4410</td>\n",
              "      <td>0.683000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4420</td>\n",
              "      <td>0.693000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4430</td>\n",
              "      <td>0.680000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4440</td>\n",
              "      <td>0.684500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4450</td>\n",
              "      <td>0.683100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4460</td>\n",
              "      <td>0.656700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4470</td>\n",
              "      <td>0.686600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4480</td>\n",
              "      <td>0.685100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4490</td>\n",
              "      <td>0.684500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.688000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4510</td>\n",
              "      <td>0.675600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4520</td>\n",
              "      <td>0.676900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4530</td>\n",
              "      <td>0.674100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4540</td>\n",
              "      <td>0.684600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4550</td>\n",
              "      <td>0.669100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4560</td>\n",
              "      <td>0.703100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4570</td>\n",
              "      <td>0.689800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4580</td>\n",
              "      <td>0.685600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4590</td>\n",
              "      <td>0.682300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.681300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4610</td>\n",
              "      <td>0.691800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4620</td>\n",
              "      <td>0.693900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4630</td>\n",
              "      <td>0.676200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4640</td>\n",
              "      <td>0.674200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4650</td>\n",
              "      <td>0.685600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4660</td>\n",
              "      <td>0.681600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4670</td>\n",
              "      <td>0.672000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4680</td>\n",
              "      <td>0.701700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4690</td>\n",
              "      <td>0.678600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.653800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4710</td>\n",
              "      <td>0.699600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4720</td>\n",
              "      <td>0.698800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4730</td>\n",
              "      <td>0.673500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4740</td>\n",
              "      <td>0.677500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4750</td>\n",
              "      <td>0.693800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4760</td>\n",
              "      <td>0.678100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4770</td>\n",
              "      <td>0.694200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4780</td>\n",
              "      <td>0.702900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4790</td>\n",
              "      <td>0.705900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.688100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4810</td>\n",
              "      <td>0.679800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4820</td>\n",
              "      <td>0.667700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4830</td>\n",
              "      <td>0.696600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4840</td>\n",
              "      <td>0.687900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4850</td>\n",
              "      <td>0.672500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4860</td>\n",
              "      <td>0.675200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4870</td>\n",
              "      <td>0.684400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4880</td>\n",
              "      <td>0.658700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4890</td>\n",
              "      <td>0.699200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.672900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4910</td>\n",
              "      <td>0.690300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4920</td>\n",
              "      <td>0.683100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4930</td>\n",
              "      <td>0.673700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4940</td>\n",
              "      <td>0.693100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4950</td>\n",
              "      <td>0.669000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4960</td>\n",
              "      <td>0.665300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4970</td>\n",
              "      <td>0.698900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4980</td>\n",
              "      <td>0.674100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4985, training_loss=0.688401022598282, metrics={'train_runtime': 2271.0981, 'train_samples_per_second': 2.195, 'train_steps_per_second': 2.195, 'total_flos': 0.0, 'train_loss': 0.688401022598282, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "y62xDO8TDJ1p"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize lists to hold training and evaluation losses and steps\n",
        "train_losses = []\n",
        "eval_losses = []\n",
        "train_steps = []\n",
        "eval_steps = []\n",
        "\n",
        "# Populate the lists from the log history\n",
        "for entry in trainer.state.log_history:\n",
        "    if 'loss' in entry:\n",
        "        train_losses.append(entry['loss'])\n",
        "        train_steps.append(entry['step'])\n",
        "    if 'eval_loss' in entry:\n",
        "        eval_losses.append(entry['eval_loss'])\n",
        "        eval_steps.append(entry['step'])\n",
        "\n",
        "# Plot the losses\n",
        "plt.plot(train_steps, train_losses, label='Train Loss')\n",
        "plt.plot(eval_steps, eval_losses, label='Eval Loss')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Evaluation Loss Over Steps')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "g08_zgJ4Chns",
        "outputId": "8efa0157-f9e3-44a6-907f-8b2b2b8d99d1"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Eval steps:\", eval_steps)\n",
        "print(\"Eval losses:\", eval_losses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_67iBmoF2_m",
        "outputId": "4084301c-cb3e-4270-98d9-ab4fff54d95a"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval steps: []\n",
            "Eval losses: []\n"
          ]
        }
      ]
    }
  ]
}